{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creditLimit', 'posEntryMode', 'posConditionCode', 'merchantCategoryCode', 'transactionType', 'cardPresent', 'isFraud']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle \n",
    "import pandas as pd\n",
    "WORK_PATH = \"/Users/welcome/Google Drive (cuong.tranus@gmail.com)/research/internship/fraud-detection\"\n",
    "feat_dict = pickle.load(open(WORK_PATH + \"/results/features_category.pkl\" ,\"rb\"))\n",
    "\n",
    "numeric_cols = feat_dict['numeric_cols']\n",
    "cat_cols = feat_dict['cat_cols']\n",
    "\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(786363, 26)\n"
     ]
    }
   ],
   "source": [
    "pd00 = pd.read_csv(WORK_PATH + \"/data/processed_data.csv\")\n",
    "print(pd00.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountNumber</th>\n",
       "      <th>customerId</th>\n",
       "      <th>creditLimit</th>\n",
       "      <th>availableMoney</th>\n",
       "      <th>transactionDateTime</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>merchantName</th>\n",
       "      <th>posEntryMode</th>\n",
       "      <th>posConditionCode</th>\n",
       "      <th>merchantCategoryCode</th>\n",
       "      <th>...</th>\n",
       "      <th>transactionType</th>\n",
       "      <th>currentBalance</th>\n",
       "      <th>cardPresent</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>date</th>\n",
       "      <th>tvt_code_0</th>\n",
       "      <th>tvt_code_1</th>\n",
       "      <th>tvt_code_2</th>\n",
       "      <th>tvt_code_3</th>\n",
       "      <th>tvt_code_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>737265056</td>\n",
       "      <td>737265056</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2016-08-13T14:27:32</td>\n",
       "      <td>98.55</td>\n",
       "      <td>Uber</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rideshare</td>\n",
       "      <td>...</td>\n",
       "      <td>PURCHASE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-13</td>\n",
       "      <td>train_0</td>\n",
       "      <td>train_1</td>\n",
       "      <td>train_2</td>\n",
       "      <td>train_3</td>\n",
       "      <td>val_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>737265056</td>\n",
       "      <td>737265056</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2016-10-11T05:05:54</td>\n",
       "      <td>74.51</td>\n",
       "      <td>AMC #191138</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>...</td>\n",
       "      <td>PURCHASE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountNumber  customerId  creditLimit  availableMoney  \\\n",
       "0      737265056   737265056         5000          5000.0   \n",
       "1      737265056   737265056         5000          5000.0   \n",
       "\n",
       "   transactionDateTime  transactionAmount merchantName  posEntryMode  \\\n",
       "0  2016-08-13T14:27:32              98.55         Uber           2.0   \n",
       "1  2016-10-11T05:05:54              74.51  AMC #191138           9.0   \n",
       "\n",
       "   posConditionCode merchantCategoryCode  ... transactionType currentBalance  \\\n",
       "0               1.0            rideshare  ...        PURCHASE            0.0   \n",
       "1               1.0        entertainment  ...        PURCHASE            0.0   \n",
       "\n",
       "  cardPresent  isFraud        date  tvt_code_0 tvt_code_1  tvt_code_2  \\\n",
       "0       False        0  2016-08-13     train_0    train_1     train_2   \n",
       "1        True        0  2016-10-11        test       test        test   \n",
       "\n",
       "   tvt_code_3  tvt_code_4  \n",
       "0     train_3       val_4  \n",
       "1        test        test  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd00.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  creditLimit   isFraud        \n",
      "                   mean    size\n",
      "0         250  0.011962   34025\n",
      "1         500  0.017161   27097\n",
      "2        1000  0.014988   36430\n",
      "3        2500  0.014795   75429\n",
      "4        5000  0.017472  201863\n",
      "5        7500  0.013175   97913\n",
      "6       10000  0.013465   56889\n",
      "7       15000  0.018269  139307\n",
      "8       20000  0.013318   68629\n",
      "9       50000  0.017240   48781\n",
      "----------------------------------------------------------------\n",
      "  posEntryMode   isFraud        \n",
      "                    mean    size\n",
      "0          2.0  0.017460  195934\n",
      "1          5.0  0.007796  315035\n",
      "2          9.0  0.023930  236481\n",
      "3         80.0  0.015704   15283\n",
      "4         90.0  0.019003   19576\n",
      "----------------------------------------------------------------\n",
      "  posConditionCode   isFraud        \n",
      "                        mean    size\n",
      "0              1.0  0.016269  628787\n",
      "1              8.0  0.012938  149634\n",
      "2             99.0  0.030400    7533\n",
      "----------------------------------------------------------------\n",
      "    merchantCategoryCode   isFraud        \n",
      "                              mean    size\n",
      "0                airline  0.034648   15412\n",
      "1                   auto  0.012609   21651\n",
      "2            cable/phone  0.000000    1382\n",
      "3          entertainment  0.011998   80098\n",
      "4               fastfood  0.009577  112138\n",
      "5                   food  0.013432   75490\n",
      "6          food_delivery  0.000000    6000\n",
      "7                   fuel  0.000000   23910\n",
      "8              furniture  0.013859    7432\n",
      "9                    gym  0.000000    2209\n",
      "10                health  0.004714   19092\n",
      "11                hotels  0.007332   34097\n",
      "12            mobileapps  0.000000   14990\n",
      "13          online_gifts  0.024246   66238\n",
      "14         online_retail  0.024427  202156\n",
      "15  online_subscriptions  0.000000   11067\n",
      "16         personal care  0.004535   18964\n",
      "17             rideshare  0.024875   51136\n",
      "18         subscriptions  0.009432   22901\n",
      "----------------------------------------------------------------\n",
      "        transactionType   isFraud        \n",
      "                             mean    size\n",
      "0  ADDRESS_VERIFICATION  0.005751   20169\n",
      "1              PURCHASE  0.016036  745193\n",
      "2              REVERSAL  0.016599   20303\n",
      "----------------------------------------------------------------\n",
      "  cardPresent   isFraud        \n",
      "                   mean    size\n",
      "0       False  0.020674  433495\n",
      "1        True  0.009791  352868\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    if col!='isFraud':\n",
    "        print( pd00.groupby(col).agg({'isFraud':[np.mean, np.size]}).reset_index())\n",
    "        print(\"----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "###\n",
    "################################################################################\n",
    "import os, re, sys, collections, datetime, dateutil\n",
    "import numpy as np, pandas as pd\n",
    "import importlib\n",
    "import math\n",
    "import calendar\n",
    "\n",
    "\n",
    "################################################################################\n",
    "### General functions\n",
    "################################################################################\n",
    "def describe_spark_df(df):\n",
    "    \"\"\"\n",
    "    Summarize pyspark dataframe. df should be cached already\n",
    "    \"\"\"\n",
    "    print(\"### Table schema & Sample. Count: %d ###\" % (df.count()))\n",
    "    x1 = df.take(1)[0]\n",
    "    x1d = x1.asDict()\n",
    "    for w in sorted(df.dtypes, key=lambda x: x[0]): print(w[0], w[1], x1d[w[0]])\n",
    "\n",
    "\n",
    "#\n",
    "def describe_dict(dictvar, title):\n",
    "    \"\"\"\n",
    "    Summarize a python dictionary\n",
    "    \"\"\"\n",
    "    print(\"### %s ###\" % str(title))\n",
    "    keylist = sorted(dictvar.keys())\n",
    "    for k in keylist: print(\"  \" + str((k, dictvar[k])))\n",
    "    return\n",
    "\n",
    "\n",
    "#\n",
    "def split_bool_arr(arr_ind, arr_ratio_one):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        arr_ind: binary array. Assume that non-zero elements are choosable boolean indices\n",
    "    Split arr_ind into two binary arrays: res_ind01 and res_ind00\n",
    "    Returns:\n",
    "        res_ind01, res_ind00: binary arrays of similar shape of arr_ind, satisfying\n",
    "            arr_ind[i]=0 => res_ind01[i]=0 and res_ind01[i]=0\n",
    "            arr_ind[i]=1 => res_ind01[i]=1 with probability arr_ratio_one and (res_ind01[i]+res_ind01[i]=1)\n",
    "    \"\"\"\n",
    "    t01_ind01 = np.nonzero(arr_ind)[0]\n",
    "    t01_ind02 = np.random.choice([0, 1], size=len(t01_ind01), p=[1 - arr_ratio_one, arr_ratio_one], replace=True)\n",
    "    res_ind01 = np.zeros(arr_ind.shape, \"bool\")\n",
    "    res_ind01[t01_ind01[t01_ind02 == 1]] = True\n",
    "    res_ind00 = np.zeros(arr_ind.shape, \"bool\")\n",
    "    res_ind00[t01_ind01[t01_ind02 == 0]] = True\n",
    "    return res_ind01, res_ind00\n",
    "\n",
    "\n",
    "#\n",
    "def get_function_from_str(func_str):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        func_str: is like ghelper.split_bool_arr\"\n",
    "    \"\"\"\n",
    "    mod_name, func_name = func_str.rsplit('.', 1)\n",
    "    mod = importlib.import_module(mod_name)\n",
    "    func = getattr(mod, func_name)\n",
    "    return func\n",
    "\n",
    "\n",
    "# ################################################################################\n",
    "# ### hdfs related\n",
    "# ################################################################################\n",
    "# def hdfs_list_and_match(\n",
    "#         hdfs_cpoint,\n",
    "#         hdfs_path,\n",
    "#         regex_match_str,\n",
    "#         regex_groupid,\n",
    "#         get_full_path=False\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Example: \n",
    "#         ghelper.hdfs_list_and_match(sysconf.conf[\"sys_hdfs_connection_point\"],\n",
    "#             \"/tanlaDataByDate\",\n",
    "#             \"sentDate=(\\d+)\",\n",
    "#             1)\n",
    "#     \"\"\"\n",
    "#     regex_match = re.compile(regex_match_str)\n",
    "#     list01 = []\n",
    "#     for s in hdfs.InsecureClient(hdfs_cpoint).list(hdfs_path):\n",
    "#         s1 = regex_match.match(s)\n",
    "#         if s1:\n",
    "#             if get_full_path:\n",
    "#                 list01.append(os.path.join(hdfs_path, str(s1.group(regex_groupid))))\n",
    "#             else:\n",
    "#                 list01.append(str(s1.group(regex_groupid)))\n",
    "\n",
    "#     list01 = sorted(list01)\n",
    "#     return list01\n",
    "\n",
    "\n",
    "# #\n",
    "# def hdfs_delete_filelist(hdfs_cpoint, filepath_list):\n",
    "#     client = hdfs.InsecureClient(hdfs_cpoint)\n",
    "#     for filepath in filepath_list:\n",
    "#         client.delete(filepath, recursive=True)\n",
    "#     return\n",
    "\n",
    "\n",
    "################################################################################\n",
    "###\n",
    "################################################################################\n",
    "def get_prev_datetime_str(s01_datetime, lag_from, lag_to, lag_step, lag_unit, input_format, output_format):\n",
    "    \"\"\"\n",
    "    Get the previous lagged datetime strings of target_datetime\n",
    "\n",
    "    Args:\n",
    "        s01_datetime: is with format=input_format\n",
    "        lag_from, lag_to: lag_from > lag_to\n",
    "        lag_unit: use numpy.datetime64/timedelta64 format (M/d/m)\n",
    "        input_format: use datetime.datetime.strptime format (e.g. %Y%m)\n",
    "        output_format:\n",
    "\n",
    "    Returns:\n",
    "        dates02: previous lagged datetime strings\n",
    "    \"\"\"\n",
    "    date01 = np.datetime64(datetime.datetime.strptime(s01_datetime, input_format), lag_unit)\n",
    "    dates02 = []\n",
    "    for i in xrange(lag_from, lag_to, lag_step):\n",
    "        dates02.append(pd.to_datetime(str(date01 - np.timedelta64(i, lag_unit))).strftime(output_format))\n",
    "    return dates02\n",
    "#\n",
    "def get_date_from_YW(input_YW, input_format=\"%YW%W\", output_format=\"%Y%m%d\"):\n",
    "    \"\"\"\n",
    "    Example: get_date_from_YW('2016W10')\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for day_in_week in range(7):\n",
    "        t0_dt = datetime.datetime.strptime(input_YW + '-%d' % day_in_week, \"%s-%%w\" % input_format)\n",
    "        output.append(t0_dt.strftime(output_format))\n",
    "    output = sorted(output)\n",
    "    return output\n",
    "#\n",
    "def get_prev_YW_from_YW(input_YW, week_delta_list, input_format=\"%YW%W\", output_format=\"%YW%W\"):\n",
    "    \"\"\"\n",
    "    Example: get_prev_YW_from_YW('2016W10', [-2,-1])\n",
    "    \"\"\"\n",
    "    output = [((datetime.datetime.strptime(input_YW + '-0', \"%s-%%w\" % input_format) + datetime.timedelta(days=(i * 7)))\n",
    "               .strftime(output_format))\n",
    "              for i in week_delta_list]\n",
    "    return output\n",
    "#\n",
    "def get_prev_YW_from_Ymd(input_Ymd, week_delta_list, input_format=\"%Y%m%d\", output_format=\"%YW%W\"):\n",
    "    \"\"\"\n",
    "    Example: get_prev_YW_from_Ymd('20161001', [-2,-1])\n",
    "    \"\"\"\n",
    "    output = [((datetime.datetime.strptime(input_Ymd, input_format) + datetime.timedelta(days=(i * 7)))\n",
    "               .strftime(output_format))\n",
    "              for i in week_delta_list]\n",
    "    return output\n",
    "#\n",
    "def get_prev_Ymd_from_YW(input_YW, week_delta_list, input_format=\"%YW%W\", output_format=\"%Y%m%d\"):\n",
    "    \"\"\"\n",
    "    Example: get_prev_Ymd_from_YW('2016W10', [-2,-1])\n",
    "    \"\"\"\n",
    "    output01 = [get_date_from_YW(prev_YW, input_format, output_format)\n",
    "                for prev_YW in get_prev_YW_from_YW(input_YW, week_delta_list, input_format, input_format)]\n",
    "    output02 = [x01 for l01 in output01 for x01 in l01]\n",
    "    return output02\n",
    "#\n",
    "def get_last_day_of_month_from_Ym(input_Ym, delta_month=0, input_format=\"%Y%m\", output_format=\"%Y%m%d\"):\n",
    "    \"\"\"\n",
    "    Example: get_last_day_of_month_from_Ym('20161001', -1)\n",
    "    \"\"\"\n",
    "    date01_nextmonth = (datetime.datetime.strptime(str(input_Ym) + '-28', input_format + \"-%d\")\n",
    "                        + dateutil.relativedelta.relativedelta(months=delta_month)\n",
    "                        + datetime.timedelta(days=4))\n",
    "    date02_lastdayofmonth = date01_nextmonth - datetime.timedelta(days=date01_nextmonth.day)\n",
    "    return date02_lastdayofmonth.strftime(output_format)\n",
    "#\n",
    "def get_last_week_of_month_from_Ym(input_Ym, delta_month=0, input_format=\"%Y%m\", output_format=\"%YW%W\"):\n",
    "    \"\"\"\n",
    "    Example: get_last_week_of_month_from_Ym('201610', -1)\n",
    "    \"\"\"\n",
    "    date01 = (datetime.datetime.strptime(str(input_Ym), input_format)\n",
    "              + dateutil.relativedelta.relativedelta(months=delta_month + 1)\n",
    "              - dateutil.relativedelta.relativedelta(days=7))\n",
    "    return date01.strftime(output_format)\n",
    "#\n",
    "def get_prev_nmonths(upto_month, nmonth_lookback=2):\n",
    "    \"\"\"\n",
    "    Example: get_prev_nmonths('201610', 2)\n",
    "    \"\"\"\n",
    "    ym = []\n",
    "    for i in range(-nmonth_lookback, 0, 1):\n",
    "        ym.append(get_last_day_of_month_from_Ym(upto_month, delta_month=i + 1)[0:6])\n",
    "    return ym\n",
    "#\n",
    "def get_prev_nmonths_upto_ymd(upto_ymd, nmonth_lookback=6):\n",
    "    \"\"\"\n",
    "    Example: get_prev_nmonths('201610', 2)\n",
    "    \"\"\"\n",
    "    upto_month = upto_ymd[0:6]\n",
    "    last_day = get_last_day_of_month_from_Ym(upto_month)\n",
    "    if last_day == upto_ymd:\n",
    "        delta = 0\n",
    "    else:\n",
    "        delta = -1\n",
    "    ym = []\n",
    "    for i in range(-nmonth_lookback+delta, 0+delta, 1):\n",
    "        ym.append(get_last_day_of_month_from_Ym(upto_month, delta_month=i+1)[0:6])\n",
    "    return ym\n",
    "#\n",
    "def get_prev_YW_upto_Ymd(input_Ymd, week_delta_list, input_format=\"%Y%m%d\", output_format=\"%YW%W\"):\n",
    "    \"\"\"\n",
    "    Example: get_prev_YW_from_Ymd('20161001', [-2,-1])\n",
    "    \"\"\"\n",
    "    # next_input_Ymd = datetime.datetime.strptime(input_Ymd, input_format) + datetime.timedelta\n",
    "    # input_Yms = ['201512', '201601', '201602', '201603']\n",
    "    # input_Ymd_list = [ghelper.get_last_day_of_month_from_Ym(input_Ym) for input_Ym in input_Yms]\n",
    "    # date_input_Ymd_list = [datetime.datetime.strptime(input_Ymd, '%Y%m%d') for input_Ymd in input_Ymd_list]\n",
    "    # input_Ymd_list = [datetime.datetime.strftime(date_input_Ymd + datetime.timedelta(1), '%Y%m%d')\n",
    "    #                    for date_input_Ymd in date_input_Ymd_list]\n",
    "    \n",
    "    next_input_Ymd = (datetime.datetime.strptime(input_Ymd, input_format) + datetime.timedelta(days=1)).strftime(input_format)\n",
    "    output = [((datetime.datetime.strptime(next_input_Ymd, input_format) + datetime.timedelta(days=(i * 7)))\n",
    "               .strftime(output_format)) for i in week_delta_list]\n",
    "    return output\n",
    "#\n",
    "def get_wdate_from_lastwdate(str_ymd):\n",
    "    yw = datetime.datetime.strptime(str_ymd, '%Y%m%d').strftime('%YW%W')\n",
    "    dates = get_date_from_YW(yw)\n",
    "    return dates\n",
    "#\n",
    "def get_prev_ndays(upto_ymd, ndays_look_back):\n",
    "    date = datetime.datetime.strptime(upto_ymd, '%Y%m%d')\n",
    "    dates = []\n",
    "    curr_date = date\n",
    "    for i in range(ndays_look_back):\n",
    "        dates.append(curr_date.strftime('%Y%m%d'))\n",
    "        curr_date -= datetime.timedelta(1)\n",
    "    dates = sorted(dates)\n",
    "    return dates\n",
    "#\n",
    "def get_lastwdate_one_year(upto_ymd):\n",
    "    \"\"\"\n",
    "    Get the last dates of each week in one year, mostly for leadgen features\n",
    "    :param upto_ymd: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    dates = []\n",
    "    end_date = datetime.datetime.strptime(upto_ymd, '%Y%m%d') - datetime.timedelta(days=360)\n",
    "    curr_date = datetime.datetime.strptime(upto_ymd)\n",
    "\n",
    "    while curr_date >= end_date:\n",
    "        dates.append(curr_date.strftime('%Y%m%d'))\n",
    "        curr_date = curr_date - datetime.timedelta(days=7)\n",
    "    return dates\n",
    "#\n",
    "def get_all_days_of_month(input_Ym):\n",
    "    \"\"\"\n",
    "    Get all dates in a month\n",
    "    \"\"\"\n",
    "    y = int(input_Ym[0:4])\n",
    "    m = int(input_Ym[4:6])\n",
    "    last_date = calendar.monthrange(y, m)[1]\n",
    "    dates = [datetime.date(y, m, d).strftime('%Y%m%d') for d in range(1, last_date + 1)]\n",
    "    return dates\n",
    "#\n",
    "def get_last_dow_upto_Ymd(input_Ymd, delta_week):\n",
    "    \"\"\"\n",
    "    get_last_dow_upto_Ymd(\"20180506\", 0) # '20180506'\n",
    "    get_last_dow_upto_Ymd(\"20180506\", -1) # '20180429'\n",
    "    get_last_dow_upto_Ymd(\"20180503\", 0) # '20180429'\n",
    "    \"\"\"\n",
    "    date01=datetime.datetime.strptime(input_Ymd, \"%Y%m%d\")\n",
    "    date02=date01+datetime.timedelta(days=-date01.weekday() -1 + (date01.weekday()/6+delta_week)*7)\n",
    "    return date02.strftime(\"%Y%m%d\")\n",
    "\n",
    "################################################################################\n",
    "### Some statistical helper\n",
    "################################################################################\n",
    "def get_gain_table(pdf01,\n",
    "                   gt_cname_target,\n",
    "                   gt_cname_target_val,\n",
    "                   gt_num_bins,\n",
    "                   gt_natural_rate,\n",
    "                   method=\"v02\"):\n",
    "    \"\"\"\n",
    "    Get the gain table\n",
    "    Args:\n",
    "        pdf01: dataframe which must have column \n",
    "            \"pred_proba\": prediction probability for the positve case\n",
    "            \"score02\" (optional): one-to-one mapping with \"pred_proba\"\n",
    "            a label column named by variable gt_cname_target\n",
    "                Label of interest would corresponds with (pdf01[gt_cname_target]=gt_cname_target_val)\n",
    "            NOTE THAT THE POSITIVE CLASS (IMPLIED BY \"pred_proba\" and \"score02\") \n",
    "                MAY NOT THE SAME AS (pdf01[gt_cname_target]=gt_cname_target_val)\n",
    "        Assume pdf01 is already sorted by descending (or ascending) score of positive class\n",
    "    Example: \n",
    "        get_gain_table(\n",
    "            pdf01=pdf01,\n",
    "            gt_cname_target=\"label\", \n",
    "            gt_cname_target_val=1, \n",
    "            gt_num_bins=10, \n",
    "            gt_natural_rate=None,\n",
    "            method=\"v02\")\n",
    "    \"\"\"\n",
    "\n",
    "    #\n",
    "    def target_count(x01, gt_cname_target_val=gt_cname_target_val):\n",
    "        return (x01 == gt_cname_target_val).sum()\n",
    "\n",
    "    if method == \"v01\":\n",
    "        #\n",
    "        pdf01[\"rank\"] = (np.floor_divide(np.arange(pdf01.shape[0]),\n",
    "                                         math.ceil(float(pdf01.shape[0]) / gt_num_bins)).astype(\"i4\"))\n",
    "        if gt_natural_rate is None:\n",
    "            gt_natural_rate = float((pdf01[gt_cname_target] == gt_cname_target_val).sum()) / pdf01.shape[0]\n",
    "        #\n",
    "        pdf02 = pdf01.groupby(\"rank\", as_index=False).agg({gt_cname_target: [\"count\", target_count]})\n",
    "        pdf02.columns = [\"%s\" % (s02) if len(s02) > 0 else s01\n",
    "                         for s01, s02 in zip(pdf02.columns.get_level_values(0), pdf02.columns.get_level_values(1))]\n",
    "        pdf02[\"ccount\"] = np.cumsum(pdf02[\"count\"])\n",
    "        pdf02[\"target_ccount\"] = np.cumsum(pdf02[\"target_count\"])\n",
    "        pdf02[\"pos_rate\"] = pdf02[\"target_count\"].astype(\"f4\") / pdf02[\"count\"]\n",
    "        pdf02[\"pos_crate\"] = pdf02[\"target_ccount\"].astype(\"f4\") / pdf02[\"ccount\"]\n",
    "        pdf02[\"pos_gain\"] = pdf02[\"pos_rate\"] / gt_natural_rate\n",
    "        pdf02[\"pos_cgain\"] = pdf02[\"pos_crate\"] / gt_natural_rate\n",
    "    elif method == \"v02\":\n",
    "        #\n",
    "        pdf01[\"rank\"] = (np.floor_divide(np.arange(pdf01.shape[0]),\n",
    "                                         math.ceil(float(pdf01.shape[0]) / gt_num_bins)).astype(\"i4\"))\n",
    "        #\n",
    "        if \"score\" in pdf01.columns:\n",
    "            pdf02 = (pdf01.groupby(\"rank\", as_index=False)\n",
    "                .agg({\n",
    "                gt_cname_target: [\"count\", target_count],\n",
    "                \"pred_proba\": [\"min\", \"max\"],\n",
    "                \"score\": [\"min\", \"max\"]\n",
    "            })\n",
    "            )\n",
    "        else:\n",
    "            pdf02 = (pdf01.groupby(\"rank\", as_index=False)\n",
    "                .agg({\n",
    "                gt_cname_target: [\"count\", target_count],\n",
    "                \"pred_proba\": [\"min\", \"max\"],\n",
    "            })\n",
    "            )\n",
    "        pdf02.columns = [\n",
    "            \"%s_%s\" % (s01, s02) if (s01 == \"score\") or (s01 == \"pred_proba\")\n",
    "            else \"%s\" % (s02) if len(s02) > 0 else s01\n",
    "            for s01, s02 in zip(pdf02.columns.get_level_values(0), pdf02.columns.get_level_values(1))]\n",
    "        pdf02[\"target_count_prow\"] = pdf02[\"target_count\"].values.astype(\"f4\") / pdf02[\"count\"]\n",
    "        pdf02[\"target_count_pcol\"] = pdf02[\"target_count\"].values.astype(\"f4\") / pdf02[\"target_count\"].sum()\n",
    "        #\n",
    "        pdf02[\"ccount\"] = np.cumsum(pdf02[\"count\"])\n",
    "        pdf02[\"target_ccount\"] = np.cumsum(pdf02[\"target_count\"])\n",
    "        pdf02[\"target_ccount_prow\"] = pdf02[\"target_ccount\"].values.astype(\"f4\") / pdf02[\"ccount\"]\n",
    "        pdf02[\"target_ccount_pcol\"] = pdf02[\"target_ccount\"].values.astype(\"f4\") / pdf02[\"target_count\"].sum()\n",
    "        #\n",
    "        pdf02[\"pos_gain\"] = (pdf02[\"target_count_pcol\"]\n",
    "                             / (pdf02[\"count\"].values.astype(\"f4\") / pdf02[\"count\"].sum()))\n",
    "        pdf02[\"pos_cgain\"] = (pdf02[\"target_ccount_pcol\"]\n",
    "                              / (pdf02[\"count\"].values.cumsum().astype(\"f4\") / pdf02[\"count\"].sum()))\n",
    "    else:\n",
    "        pdf02 = None\n",
    "    #\n",
    "    return pdf02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date\n",
       "0  2016-08-13\n",
       "1  2016-10-11"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd00[['date']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>2016-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>2016-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>2016-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>2016-12-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week        date\n",
       "0    32  2016-08-13\n",
       "1    41  2016-10-11\n",
       "2    45  2016-11-08\n",
       "3    49  2016-12-10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "def get_week(date):\n",
    "    y,m, d = date.split(\"-\")\n",
    "    return datetime.date(int(y), int(m), int(d)).isocalendar()[1]\n",
    "\n",
    "\n",
    "pd00['week'] = pd00['date'].apply(get_week)\n",
    "pd00[['week','date']].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
